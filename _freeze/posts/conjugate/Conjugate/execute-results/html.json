{
  "hash": "0983b476a3b149affaa470c24357b070",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Conjugate Priors: Harnessing Closed-Form Solutions in Bayesian Inference'  \nauthor: \"Maciej Nasinski\"  \ndate: \"2024-12-08\"  \ncategories: [statistics]  \nimage: main.jpg\nfilters:\n  - webr\n---\n\n\n\n**TL;DR**: Conjugate priors are special prior distributions in Bayesian inference that, when combined with a given likelihood, yield a posterior in the same family as the prior. This leads to **closed-form solutions** for posterior calculations, making Bayesian updating straightforward and computationally simple. Classic examples include Beta–Binomial, Gamma–Poisson, and Normal–Normal pairs. These closed-form updates offer both computational efficiency and clear mathematical intuition, and remain valuable even in the age of advanced computational tools.\n\n## What Is a Conjugate Prior?\n\nIn Bayesian inference, the choice of prior distribution affects how we update our beliefs once data arrive. While today’s methods—like MCMC or variational inference—can handle almost any prior, **conjugate priors** remain special. Conjugate priors lead to posterior distributions of the same parametric form as the prior, resulting in closed-form solutions that are both elegant and easy to compute.\n\nA **conjugate prior** for a given likelihood is a prior distribution that, after observing data, produces a posterior distribution in the same distributional family as the prior. If your model is from an exponential family, conjugate priors often exist that simplify Bayesian updating to mere formula substitutions. For more details, see the [Wikipedia entry on Conjugate Priors](https://en.wikipedia.org/wiki/Conjugate_prior).\n\n## Why Are Conjugates Great?\n\n1. **Closed-Form Posterior:**  \n   With conjugate priors, no numerical approximations are needed to find the posterior. You get direct formulas for the updated parameters.\n\n2. **Computational Efficiency:**  \n   Conjugates were invaluable before powerful computers and remain useful today, especially when you need quick analyses or have limited computational resources.\n\n3. **Analytical Insights:**  \n   Conjugates show exactly how the prior parameters and observed data combine. They give transparent, interpretable formulas for how each new data point shifts the posterior.\n\n4. **Educational Value:**  \n   Conjugate models are perfect for learning Bayesian inference. They let students see Bayesian updating without the distraction of complex computation.\n\n## Example 1: Beta–Binomial Conjugacy\n\n**Scenario:** You observe $X$ successes out of $n$ Bernoulli trials with unknown success probability $p$.\n\n- **Prior:** $p \\sim \\text{Beta}(\\alpha, \\beta)$\n- **Likelihood:** $X \\mid p \\sim \\text{Binomial}(n, p)$\n\n**Posterior:**\n$$\np \\mid X \\sim \\text{Beta}(\\alpha + X, \\beta + n - X).\n$$\n\n**Numeric Example:**\n\n- Suppose you start with a prior $p \\sim \\text{Beta}(\\alpha=2, \\beta=2)$, which is somewhat informative but still flexible.\n- You run $n=10$ trials and observe $X=7$ successes.\n\nYour posterior is:\n$$\np \\mid X=7 \\sim \\text{Beta}(2+7, 2+(10-7)) = \\text{Beta}(9, 5).\n$$\n\nThis gives you a posterior that incorporates your initial beliefs and the observed data seamlessly.\n\n**Quick R Code (with webr):**\n\nBelow is a code cell you can run if you’re viewing this in a Quarto or Jupyter environment with **webr** enabled:\n\n\n\n::: {.cell browser='true'}\n\n```{.r .cell-code}\n# Install if needed: install.packages(\"webr\")\n\nalpha <- 2\nbeta <- 2\nn <- 10\nX <- 7\n\n# Posterior parameters\nalpha_post <- alpha + X\nbeta_post <- beta + n - X\n\n# Let's plot the posterior\ncurve(dbeta(x, alpha_post, beta_post), from=0, to=1,\n      main = \"Posterior Beta(9,5) distribution\",\n      xlab = \"p\", ylab = \"Density\")\nabline(v=X/n, col=\"red\", lwd=2) # Mark the sample proportion 0.7\n```\n\n::: {.cell-output-display}\n![](Conjugate_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n## Example 2: Gamma–Poisson Conjugacy\n\n**Scenario:** You count events from a Poisson process with unknown rate $\\lambda$.\n\n- **Prior:** $\\lambda \\sim \\text{Gamma}(\\alpha, \\beta)$\n- **Likelihood:** $X_i \\sim \\text{Poisson}(\\lambda)$\n\nAfter observing counts $x_1, \\ldots, x_n$:\n$$\n\\lambda \\mid x_1,\\ldots,x_n \\sim \\text{Gamma}\\left(\\alpha + \\sum_{i=1}^n x_i, \\beta + n\\right).\n$$\n\n**Numeric Example:**\n\n- Suppose $\\lambda$ has a prior $\\text{Gamma}(\\alpha=1, \\beta=1)$, a fairly uninformative choice.\n- You observe $n=5$ counts: $x = (2,3,4,1,5)$.\n\nTotal counts: $\\sum x_i = 2+3+4+1+5 = 15$.\n\nPosterior:\n$$\n\\lambda \\mid data \\sim \\text{Gamma}(1+15, 1+5) = \\text{Gamma}(16,6).\n$$\n\nThis new gamma distribution reflects both your prior (which allowed for a wide range of $\\lambda$) and the observed data (averaging 3 events per observation, pushing the rate estimate up).\n\n## Example 3: Normal–Normal Conjugacy\n\n**Scenario:** You have normal data with known variance $\\sigma^2$ but unknown mean $\\mu$.\n\n- **Prior:** $\\mu \\sim N(m_0, s_0^2)$\n- **Likelihood:** $X_i \\sim N(\\mu, \\sigma^2)$\n\nAfter observing $x_1,\\ldots,x_n$:\n$$\n\\mu \\mid x_1,\\ldots,x_n \\sim N(m_n, s_n^2),\n$$\nwhere:\n$$\n\\frac{1}{s_n^2} = \\frac{1}{s_0^2} + \\frac{n}{\\sigma^2}, \\quad\nm_n = \\frac{\\frac{m_0}{s_0^2} + \\frac{n\\overline{x}}{\\sigma^2}}{\\frac{1}{s_0^2} + \\frac{n}{\\sigma^2}}.\n$$\n\n**Numeric Example:**\n\n- Prior: $\\mu \\sim N(m_0=0, s_0^2=1)$\n- Observed data: $x = (1.2, 0.8, 1.0, 1.5)$, so $n=4$ and $\\overline{x}=1.125$.\n- Known variance: $\\sigma^2 = 0.5^2 = 0.25$.\n\nCompute posterior parameters:\n$$\n\\frac{1}{s_n^2} = \\frac{1}{1} + \\frac{4}{0.25} = 1 + 16 = 17.\n$$\nThus, $s_n^2 = 1/17 \\approx 0.0588.$\n\nPosterior mean:\n$$\nm_n = \\frac{\\frac{0}{1} + \\frac{4 \\cdot 1.125}{0.25}}{1 + \\frac{4}{0.25}} = \\frac{0 + \\frac{4 \\cdot 1.125}{0.25}}{17} = \\frac{18}{17} \\approx 1.0588.\n$$\n\nYour posterior for $\\mu$ is approximately $N(1.0588, 0.0588)$, reflecting that the data (with mean around 1.125) pulled your initially neutral prior (mean 0) toward the sample mean, reducing uncertainty.\n\n**Quick R Code (with webr):**\n\n\n\n::: {.cell browser='true'}\n\n```{.r .cell-code}\nm0 <- 0\ns0_sq <- 1\nsigma_sq <- 0.25\nx <- c(1.2, 0.8, 1.0, 1.5)\nn <- length(x)\nxbar <- mean(x)\n\ninv_s_n_sq <- 1/s0_sq + n/sigma_sq\ns_n_sq <- 1/inv_s_n_sq\nm_n <- (m0/s0_sq + n*xbar/sigma_sq)/inv_s_n_sq\n\ncat(\"Posterior Mean:\", m_n, \"\\nPosterior Variance:\", s_n_sq, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPosterior Mean: 1.058824 \nPosterior Variance: 0.05882353 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Density plot of posterior\ncurve(dnorm(x, mean = m_n, sd = sqrt(s_n_sq)), \n      from=m_n-3*sqrt(s_n_sq), to=m_n+3*sqrt(s_n_sq),\n      main=\"Posterior for mu (Normal-Normal)\",\n      xlab=\"mu\", ylab=\"Density\")\nabline(v=xbar, col=\"red\", lwd=2) # observed sample mean\nabline(v=m0, col=\"blue\", lwd=2, lty=2) # prior mean\n```\n\n::: {.cell-output-display}\n![](Conjugate_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n## Beyond the Classics\n\nThe above three examples—Beta–Binomial, Gamma–Poisson, and Normal–Normal—are the canonical illustrations of conjugate priors. Many other conjugate relationships exist, especially within the exponential family of distributions. Though not all models admit conjugates, they’re invaluable whenever they apply.\n\n## Conclusion\n\nConjugate priors offer a clean, closed-form pathway to Bayesian updating. They blend prior and data into a neat posterior distribution without needing numerical methods. For classic scenarios, this results in quick, exact inference and deep insights into how parameters shift after seeing new data. Even as Bayesian analysis grows more complex, these conjugate pairs remain foundational examples of Bayesian elegance and efficiency.",
    "supporting": [
      "Conjugate_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}